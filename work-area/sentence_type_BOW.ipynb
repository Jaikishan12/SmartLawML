{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport glob\nimport numpy as np\nimport pandas as pd\nimport csv\nimport string\nimport re\nimport math\nimport sklearn as sk\nimport nltk\nimport heapq\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import TfidfTransformer# This Python 3 environment comes with many helpful analytics libraries installed\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:33.011941Z","iopub.execute_input":"2022-04-26T13:43:33.012872Z","iopub.status.idle":"2022-04-26T13:43:33.025873Z","shell.execute_reply.started":"2022-04-26T13:43:33.012827Z","shell.execute_reply":"2022-04-26T13:43:33.025169Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:33.196103Z","iopub.execute_input":"2022-04-26T13:43:33.197897Z","iopub.status.idle":"2022-04-26T13:43:33.204471Z","shell.execute_reply.started":"2022-04-26T13:43:33.197829Z","shell.execute_reply":"2022-04-26T13:43:33.203403Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"train_files = glob.glob(\"../input/sample1/SmartLawDataset-main/json/*.json\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:33.268286Z","iopub.execute_input":"2022-04-26T13:43:33.268728Z","iopub.status.idle":"2022-04-26T13:43:33.279920Z","shell.execute_reply.started":"2022-04-26T13:43:33.268697Z","shell.execute_reply":"2022-04-26T13:43:33.279137Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"mergejson=pd.DataFrame()\nfor file in train_files:\n    with open(file) as f1: \n        data1 = json.load(f1)\n    df1=pd.DataFrame([data1])\n    mergejson=pd.concat([mergejson,df1])\nmg1=mergejson.drop(['header','background','order','footer','annotationProcessingStage','annotationProcessingStageAnnotations','processedText'], axis=1)\nmg1.to_csv('file2.csv')\n#print(mergejson)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:33.305004Z","iopub.execute_input":"2022-04-26T13:43:33.305434Z","iopub.status.idle":"2022-04-26T13:43:33.681474Z","shell.execute_reply.started":"2022-04-26T13:43:33.305403Z","shell.execute_reply":"2022-04-26T13:43:33.680495Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"header=['ARGUMENT','TYPE']\nfilename = 'final_argument_by.csv'\ndata1=[]\n\nwith open(filename, 'w') as file:\n    csvwriter = csv.writer(file) # 2. create a csvwriter object\n    csvwriter.writerow(header) # 4. write the header\n    for j in mg1['arguments']:\n        for k in j:           \n            for p in k['argumentSentences']:                \n                data=[]\n                if(p['argumentSentenceType']=='NA'):\n                    continue\n                data.append(p['text'][:])\n                data.append(p['argumentSentenceType'])\n                data1.append(data)\n    csvwriter.writerows(data1) # 5. write the rest of the data\ndataset = pd.read_csv('final_argument_by.csv')\ndf = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:33.683148Z","iopub.execute_input":"2022-04-26T13:43:33.683474Z","iopub.status.idle":"2022-04-26T13:43:33.714116Z","shell.execute_reply.started":"2022-04-26T13:43:33.683443Z","shell.execute_reply":"2022-04-26T13:43:33.713475Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"s =  set(string.punctuation)\ns.add('\\xad')\nnltk_stopwords = set(stopwords.words('english'))\nfor index, row in df.iterrows():\n    row['ARGUMENT']=row['ARGUMENT'].lower()\n    for x in row['ARGUMENT']:\n        if x in s or re.search(r'-?\\d+', x):\n            row['ARGUMENT']=row['ARGUMENT'].replace(x,\"\").strip()\nfor index, row in df.iterrows():\n    for x in row['ARGUMENT'].split():\n        if x in nltk_stopwords:\n            row['ARGUMENT']=row['ARGUMENT'].replace(x,\"\").strip()\n        \n#Now we have proper dataset after removing unwanted punctuations etc\narr=[]\narr1=[]\ncount=0\nc1=0\nfor index, row in df.iterrows():\n    if(row['TYPE']=='PREMISE'):\n        count+=1\n        if(count>290):\n            continue\n    arr.append(row['ARGUMENT'])\n    arr1.append(row['TYPE'])\n\ndf1=pd.DataFrame()\ndf1[\"argument\"] = arr\ndf1[\"by\"] = arr1\nprint(df1)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:33.715152Z","iopub.execute_input":"2022-04-26T13:43:33.715801Z","iopub.status.idle":"2022-04-26T13:43:34.675321Z","shell.execute_reply.started":"2022-04-26T13:43:33.715755Z","shell.execute_reply":"2022-04-26T13:43:34.674452Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"count_vect = CountVectorizer()\nX_counts = count_vect.fit_transform(df1['argument'])\ncolumns=count_vect.get_feature_names_out()\nfin_x=pd.DataFrame(X_counts.toarray(), columns=count_vect.get_feature_names_out())\nprint(fin_x)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:34.677387Z","iopub.execute_input":"2022-04-26T13:43:34.677633Z","iopub.status.idle":"2022-04-26T13:43:34.705074Z","shell.execute_reply.started":"2022-04-26T13:43:34.677600Z","shell.execute_reply":"2022-04-26T13:43:34.704365Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"final_by=[]\nfor item in df1['by']:\n    final_by.append(item)\nheader=columns\nfilename = 'final_csv_1.csv'\ndata1=[]\nwith open(filename, 'w',encoding=\"UTF-8\") as file:\n    csvwriter = csv.writer(file) # 2. create a csvwriter object\n    csvwriter.writerow(header) # 4. write the header\n    for item in X_counts.toarray():\n        data1.append(item)\n    csvwriter.writerows(data1) # 5. write the rest of the data\nfinal_bow=pd.read_csv(filename)\nfinal_bow['TYpe']=df1['by']\nfinal_bow","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:34.706452Z","iopub.execute_input":"2022-04-26T13:43:34.706967Z","iopub.status.idle":"2022-04-26T13:43:35.474208Z","shell.execute_reply.started":"2022-04-26T13:43:34.706923Z","shell.execute_reply":"2022-04-26T13:43:35.473312Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"final_bow = final_bow.dropna(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.475697Z","iopub.execute_input":"2022-04-26T13:43:35.475930Z","iopub.status.idle":"2022-04-26T13:43:35.491869Z","shell.execute_reply.started":"2022-04-26T13:43:35.475900Z","shell.execute_reply":"2022-04-26T13:43:35.490937Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"y=final_bow.TYpe\nfeatures=header\nx=final_bow[features]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.492858Z","iopub.execute_input":"2022-04-26T13:43:35.493421Z","iopub.status.idle":"2022-04-26T13:43:35.503019Z","shell.execute_reply.started":"2022-04-26T13:43:35.493382Z","shell.execute_reply":"2022-04-26T13:43:35.502345Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n# check the shape of X_train and X_test\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.504026Z","iopub.execute_input":"2022-04-26T13:43:35.504474Z","iopub.status.idle":"2022-04-26T13:43:35.528922Z","shell.execute_reply.started":"2022-04-26T13:43:35.504403Z","shell.execute_reply":"2022-04-26T13:43:35.527866Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.530353Z","iopub.execute_input":"2022-04-26T13:43:35.530612Z","iopub.status.idle":"2022-04-26T13:43:35.564194Z","shell.execute_reply.started":"2022-04-26T13:43:35.530569Z","shell.execute_reply":"2022-04-26T13:43:35.563535Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"y_pred = gnb.predict(X_test)\ny_pred_train = gnb.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.566393Z","iopub.execute_input":"2022-04-26T13:43:35.566940Z","iopub.status.idle":"2022-04-26T13:43:35.620853Z","shell.execute_reply.started":"2022-04-26T13:43:35.566909Z","shell.execute_reply":"2022-04-26T13:43:35.620221Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.621956Z","iopub.execute_input":"2022-04-26T13:43:35.622218Z","iopub.status.idle":"2022-04-26T13:43:35.628175Z","shell.execute_reply.started":"2022-04-26T13:43:35.622185Z","shell.execute_reply":"2022-04-26T13:43:35.627314Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"print(y_test.value_counts())\nnull_accuracy = (76/(69+76))\nprint('Null accuracy score: {0:0.4f}'. format(null_accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.629735Z","iopub.execute_input":"2022-04-26T13:43:35.630387Z","iopub.status.idle":"2022-04-26T13:43:35.644140Z","shell.execute_reply.started":"2022-04-26T13:43:35.630246Z","shell.execute_reply":"2022-04-26T13:43:35.643150Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"#SVC model\nlsvc = LinearSVC(verbose=0)\nprint(lsvc)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.645532Z","iopub.execute_input":"2022-04-26T13:43:35.646341Z","iopub.status.idle":"2022-04-26T13:43:35.656906Z","shell.execute_reply.started":"2022-04-26T13:43:35.646248Z","shell.execute_reply":"2022-04-26T13:43:35.656016Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n          verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.658303Z","iopub.execute_input":"2022-04-26T13:43:35.658562Z","iopub.status.idle":"2022-04-26T13:43:35.671252Z","shell.execute_reply.started":"2022-04-26T13:43:35.658531Z","shell.execute_reply":"2022-04-26T13:43:35.670616Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"lsvc.fit(X_train, y_train)\nscore = lsvc.score(X_train, y_train)\nprint(\"Score: \", score)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.672562Z","iopub.execute_input":"2022-04-26T13:43:35.673013Z","iopub.status.idle":"2022-04-26T13:43:35.737060Z","shell.execute_reply.started":"2022-04-26T13:43:35.672970Z","shell.execute_reply":"2022-04-26T13:43:35.736131Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors= 3) # k=3\nknn.fit(X_train,y_train)\nprediction = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.738620Z","iopub.execute_input":"2022-04-26T13:43:35.739198Z","iopub.status.idle":"2022-04-26T13:43:35.819978Z","shell.execute_reply.started":"2022-04-26T13:43:35.739145Z","shell.execute_reply":"2022-04-26T13:43:35.818996Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"print(\"{} nÄ±n score: {}\".format(3,knn.score(X_test,y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.821733Z","iopub.execute_input":"2022-04-26T13:43:35.822318Z","iopub.status.idle":"2022-04-26T13:43:35.876629Z","shell.execute_reply.started":"2022-04-26T13:43:35.822248Z","shell.execute_reply":"2022-04-26T13:43:35.875691Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"def learn_curve(X,y,c):\n    le = preprocessing.LabelEncoder() # Label encoding the target\n    sc = preprocessing.StandardScaler() # Scaling the input features\n    y = le.fit_transform(y)#Label Encoding the target\n    log_reg = LogisticRegression(max_iter=200,random_state=11,C=c)\n    lr = Pipeline(steps=(['scaler',sc],\n                        ['classifier',log_reg]))\n    \n    \n    cv = StratifiedKFold(n_splits=5,random_state=11,shuffle=True) # Creating a StratifiedKFold object with 5 folds\n    cv_scores = cross_val_score(lr,X,y,scoring=\"accuracy\",cv=cv) # Storing the CV scores (accuracy) of each fold\n    lr.fit(X,y) # Fitting the model\n    train_score = lr.score(X,y) # Scoring the model on train set\n    #Building the learning curve\n    train_size,train_scores,test_scores = learning_curve(estimator=lr,X=X,y=y,cv=cv,scoring=\"accuracy\",random_state=11)\n    train_scores = 1-np.mean(train_scores,axis=1)#converting the accuracy score to misclassification rate\n    test_scores = 1-np.mean(test_scores,axis=1)#converting the accuracy score to misclassification rate\n    lc = pd.DataFrame({\"Training_size\":train_size,\"Training_loss\":train_scores,\"Validation_loss\":test_scores}).melt(id_vars=\"Training_size\")\n    return {\"cv_scores\":cv_scores,\n           \"train_score\":train_score,\n           \"learning_curve\":lc}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.878396Z","iopub.execute_input":"2022-04-26T13:43:35.878918Z","iopub.status.idle":"2022-04-26T13:43:35.895647Z","shell.execute_reply.started":"2022-04-26T13:43:35.878868Z","shell.execute_reply":"2022-04-26T13:43:35.894584Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"lc = learn_curve(x,y,1)\nprint(f'Cross Validation Accuracies:\\n{\"-\"*25}\\n{list(lc[\"cv_scores\"])}\\n\\n\\\nMean Cross Validation Accuracy:\\n{\"-\"*25}\\n{np.mean(lc[\"cv_scores\"])}\\n\\n\\\nStandard Deviation of Cross Validation Accuracy:\\n{\"-\"*25}\\n{np.std(lc[\"cv_scores\"])}\\n\\n\\\nTraining Accuracy:\\n{\"-\"*15}\\n{lc[\"train_score\"]}\\n\\n')\nsns.lineplot(data=lc[\"learning_curve\"],x=\"Training_size\",y=\"value\",hue=\"variable\")\nplt.title(\"Learning Curve of Model\")\nplt.ylabel(\"Misclassification Rate/Loss\");","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:43:35.897595Z","iopub.execute_input":"2022-04-26T13:43:35.898389Z","iopub.status.idle":"2022-04-26T13:43:41.291143Z","shell.execute_reply.started":"2022-04-26T13:43:35.898332Z","shell.execute_reply":"2022-04-26T13:43:41.290336Z"},"trusted":true},"execution_count":233,"outputs":[]}]}