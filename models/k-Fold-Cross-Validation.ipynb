{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e8a530",
   "metadata": {},
   "source": [
    "Reference:\n",
    "https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/\n",
    "\n",
    "https://www.kaggle.com/code/muhammetvarl/mlp-multiclass-classification-roc-auc/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201e0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from smartlawdata import getSentenceTypeDataSet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_final1 = getSentenceTypeDataSet()\n",
    "#print(df_final1)\n",
    "\n",
    "los=[]\n",
    "for item in df_final1['text']:\n",
    "    los.append(item)\n",
    "\n",
    "#Create a TFIDF vectorizer to generate text entered into vector form to be given as input to Machine Learning model\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(los)\n",
    "feature_names = vectorizer.get_feature_names_out() #Extract the feature names as columns for the texts\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_end = pd.DataFrame(denselist, columns=feature_names)\n",
    "df_end['argumentSentenceType']=df_final1['argumentSentenceType']\n",
    "\n",
    "yoriginal=df_end.argumentSentenceType\n",
    "Xoriginal=df_end[feature_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04b23f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import isnan\n",
    "from numpy import asarray\n",
    "from numpy import polyfit\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# create the dataset\n",
    "def get_dataset(X,y,n_samples=100):\n",
    "    #X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X.sample(n_samples), y.sample(n_samples)\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression()) #\n",
    "    #models.append(RidgeClassifier())\n",
    "    #models.append(SGDClassifier())\n",
    "    #models.append(PassiveAggressiveClassifier())\n",
    "    #models.append(KNeighborsClassifier()) #\n",
    "    #models.append(DecisionTreeClassifier()) #\n",
    "    #models.append(LinearSVC())\n",
    "    #models.append(SVC()) #\n",
    "    #models.append(GaussianNB())\n",
    "    #models.append(AdaBoostClassifier())\n",
    "    #models.append(BaggingClassifier())\n",
    "    #models.append(RandomForestClassifier()) #\n",
    "    #models.append(ExtraTreesClassifier()) #\n",
    "    #models.append(GaussianProcessClassifier())\n",
    "    #models.append(GradientBoostingClassifier()) #\n",
    "    #models.append(LinearDiscriminantAnalysis())\n",
    "    #models.append(QuadraticDiscriminantAnalysis())\n",
    "    return models\n",
    "\n",
    "def evaluate_model_LOOCV(X, y, model): \n",
    "    # evaluate the model\n",
    "    cv = LeaveOneOut()\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print('LOOCV accuracy=%.3f (%.3f,%.3f)' % (mean(scores), scores.min(), scores.max()))\n",
    "    # return scores    \n",
    "    return float(\"{:.4f}\".format(mean(scores))), float(\"{:.4f}\".format(scores.min())), float(\"{:.4f}\".format(scores.max()))\n",
    "\n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model_CV(X, y, num_folds, model):        \n",
    "    # evaluate the model\n",
    "    cv = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return float(\"{:.4f}\".format(mean(scores))), float(\"{:.4f}\".format(scores.min())), float(\"{:.4f}\".format(scores.max()))\n",
    "\n",
    "def getBestModelCV(Xoriginal,yoriginal):\n",
    "    # get the list of models to consider\n",
    "    models = get_models()\n",
    "    # evaluate each model\n",
    "    X_size=Xoriginal.shape[0]\n",
    "    n_samples_list = list()\n",
    "    n_samples_list.append(50)\n",
    "    #n_samples_list.append(int(X_size*0.1))\n",
    "    #n_samples_list.append(int(X_size*0.2))\n",
    "    #n_samples_list.append(int(X_size*0.3))\n",
    "    #n_samples_list.append(int(X_size*0.4))\n",
    "    #n_samples_list.append(int(X_size*0.5))    \n",
    "    \n",
    "    out = list()\n",
    "    \n",
    "    iter = 1\n",
    "    for n_samples in n_samples_list:        \n",
    "        # collect results\n",
    "        all_model_out = list()\n",
    "        ideal_results_all_models, cv_results_all_models = list(), list()\n",
    "        # get the dataset\n",
    "        X, y = get_dataset(Xoriginal,yoriginal,n_samples)\n",
    "        print(\"(X,y) shape\",X.shape,y.shape)\n",
    "        for model in models: \n",
    "            print(\"Evaluating Model:\",type(model).__name__)\n",
    "            #Evaluate Ideal case\n",
    "            ideal_mean,ideal_min,ideal_max = evaluate_model_LOOCV(X,y, model)            \n",
    "            #Evaluate cross validation\n",
    "            cv_results_current_model = list()\n",
    "            current_model_cv_out = list()\n",
    "            num_folds = range(2,11) \n",
    "            for k in num_folds:\n",
    "                cv_mean,cv_min,cv_max = evaluate_model_CV(X,y,k,model)\n",
    "                # store results\n",
    "                cv_results_current_model.append(cv_mean)                \n",
    "                print('> fold=%d, accuracy=%.3f (%.3f,%.3f)' % (k, cv_mean,cv_min,cv_max))\n",
    "                current_model_cv_out.append({'fold':k,'meanAccuracy':cv_mean,'minAccuracy':cv_min,'maxAccuracy':cv_max})\n",
    "              \n",
    "            # check for invalid results\n",
    "            if isnan(mean(cv_results_current_model)) or isnan(ideal_mean):\n",
    "                continue\n",
    "            \n",
    "            ideal_results_all_models.append(ideal_mean)\n",
    "            cv_results_all_models.append(mean(cv_results_current_model))\n",
    "            # summarize progress\n",
    "            #print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "            all_model_out.append({'modelName':type(model).__name__,'meanLOOCV':ideal_mean,'mean10FoldCV':float(\"{:.4f}\".format(mean(cv_results_current_model))),\"foldWiseResult\":current_model_cv_out})\n",
    "        #print('Mean LOOCV =%.3f, Mean 10-fold CV =%.3f' % (mean(ideal_results),mean(cv_results)))   \n",
    "        out.append({'iterationNumber':iter,'noOfSamples':n_samples,'meanLOOCVAllModels':float(\"{:.4f}\".format(mean(ideal_results_all_models))),'mean10FoldCVAllModels':float(\"{:.4f}\".format(mean(cv_results_all_models))),'mlModelResultList':all_model_out})\n",
    "        #out.append({'iterationNumber':iter,'noOfSamples':n_samples,'meanLOOCVAllModels':mean(ideal_results),'mean10FoldCVAllModels':mean(cv_results)})\n",
    "        iter = iter + 1 \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ae8105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(X,y) shape (50, 4891) (50,)\n",
      "Evaluating Model: LogisticRegression\n",
      "LOOCV accuracy=0.800 (0.000,1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=2, accuracy=0.800 (0.800,0.800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=3, accuracy=0.800 (0.765,0.824)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=4, accuracy=0.801 (0.769,0.833)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=5, accuracy=0.800 (0.800,0.800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=6.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=6, accuracy=0.801 (0.750,0.875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=7, accuracy=0.801 (0.714,0.857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=8, accuracy=0.804 (0.714,0.833)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=9.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=9, accuracy=0.800 (0.667,0.833)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\git\\SmartLawML\\smartlawml-microservice\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> fold=10, accuracy=0.800 (0.800,0.800)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mgetBestModelCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mgetBestModelCV\u001b[1;34m(Xoriginal, yoriginal)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# summarize progress\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m#print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     all_model_out\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelName\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanLOOCV\u001b[39m\u001b[38;5;124m'\u001b[39m:ideal_mean,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean10FoldCV\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mean(cv_results_current_model))),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoldWiseResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:current_model_cv_out})\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params_\u001b[49m))\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m#print('Mean LOOCV =%.3f, Mean 10-fold CV =%.3f' % (mean(ideal_results),mean(cv_results)))   \u001b[39;00m\n\u001b[0;32m    122\u001b[0m out\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterationNumber\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28miter\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoOfSamples\u001b[39m\u001b[38;5;124m'\u001b[39m:n_samples,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanLOOCVAllModels\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mean(ideal_results_all_models))),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean10FoldCVAllModels\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mean(cv_results_all_models))),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlModelResultList\u001b[39m\u001b[38;5;124m'\u001b[39m:all_model_out})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "out = getBestModelCV(X,y)\n",
    "#print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
